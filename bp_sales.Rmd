---
title: "An Analysis of Budapest Property Market"
author: "Benoît Guillaud"
date: "2 Dezember 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(corrgram)
#library("vcd")
library(caTools)
#library("psych)
library(rpart)          # implements CART (regression trees)
library(rpart.plot)
library(caret)
library(e1071)          # skewness
library(kernlab)        # support vector machine 
library(pROC)	          # plot the ROC curves
library(ggplot2)

```

## Present and prepare the data
### Origin of the data
The dataset analysed was scraped from www.ingatlan.com, a popular platform in Hungary for property listings, using a Python code based on the library BeautifulSoup.

The following assumptions are made when carrying out the search:
 - Limit the search to 3 inner-city districts (V. VI. and VII. kerület)
 - Limit the search to brickwork building (the vast majority in these districts) 
 - Set "tenancy for sale" = NO, as I don't understand it 

The resulting search url is: 
http://ingatlan.com/listar/elado+lakas+nem-berleti-jog+tegla-epitesu-lakas+budapest+v-vi-vii-ker 

### Features
The following features are extracted frome the listings:

| Feature   | Description                                 | Type    |
|-----------|---------------------------------------------|---------|
| listing   | Number of the listing                       | ID      |
| price     | Asking price in million Forint (HUF)        | Float   |
| area      | Flat floor area (mezzanine NOT included)    | Integer |
| rooms     | Number of rooms                             | String  |
| fullrooms | Number of full rooms                        | Integer |
| halfrooms | Number of half rooms                        | Integer |
| district  | District wehre the property is located      | String  |
| varos     | Administrative division inside the district | String  |
| condition | Condition of the property                   | String  |
| floor     | Floor (0={földszint,fél} -1={underground})  | Integer |
| storeys   | Number of storeys in the building           | Integer |
| lift      | Presence of an elevator                     | Boolean |
| heating   | Type of heating                             | String  |
| view      | Opening to the street or internal yard etc. | String  |
| lat       | Latitude of the property                    | Float   |
| long      | Longitude of the property                   | Float   |
| orient    | Orientation of the windows                  | String  |
| parking   | Options for parking, if any                 | String  |
| balcony   | Whether there is a balcony or not           | Boolean |
| aircon    | Whether these is air conditioning           | Boolean |
| ceiling   | Ceiling height                              | Boolean |
| utility   | Utility level as classified by ingatlan.com | String  |
| bathtoil  | Whether bathroom and toilets are together   | String  |
| garcess   | Whether there is garden access              | Boolean |

Features not collected include the street, as they usually span across long distances in Budapest.

* It may be interesting to list  here for each feature the possible values *

### Load the data
```{r}
sales <- read.csv("extraction v4 - 2016-12-04.txt", fileEncoding="UTF-8-BOM", header=TRUE, sep=";")
dim(sales)
str(sales)
```

### Clean the data
Set the listing number (first column) as the case identifier (i.e. row name) and then delete it from the dataset:
```{r}
rownames(sales) <- sales$listing
sales <- dplyr::select(sales,-listing)
```

We want to remove duplicates in the data (redundant listings exists because some properties are uploaded several times by various agencies):
```{r}
# find duplicates against features selected simultaneously
feat <- c(2,3,4,7,10,15,16) # price, area, rooms, district, floor, lat, long
dupl <- duplicated(sales[,feat])
# count the number of duplicates "TRUE"
table(dupl)
# keep only the unique rows
sales = subset(sales,!dupl)
dim(sales)
```

Remove some spurious data in the set (other districts):
```{r}
sales <- dplyr::filter(sales, district=='5. ker'|district=='6. ker'|district=='7. ker')
```

Clean the "nincs megadva" from the data (replace by NA):
```{r}
sales <- within(sales, {
  condition[condition == "nincs megadva"] <- NA
  lift[lift == "nincs megadva"] <- NA
  heating[heating == "nincs megadva"] <- NA
  view[view == "nincs megadva"] <- NA
  orient[orient == "nincs megadva"] <- NA
  floor[floor == "nincs megadva"] <- NA
  storeys[storeys == "nincs megadva"] <- NA
  parking[parking == "nincs megadva"] <- NA
  aircon[aircon == "nincs megadva"] <- NA
  ceiling[ceiling == "nincs megadva"] <- NA
  utility[utility == "nincs megadva"] <- NA
  bathtoil[bathtoil == "nincs megadva"] <- NA
  garcess[garcess == "nincs megadva"] <- NA
  })
```

Recode the categories of the factor variable "varos":
```{r}
table(sales$varos)
sales <- within(sales, {
  # using simple assignments
  varos[varos == ""] <- NA
  varos[varos == "Terézváros"] <- NA
  varos[varos == "Erzsébetváros"] <- NA
  })
```

Recode the categories of the factor variable "condition":
```{r}
table(sales$condition)
sales$condition <- dplyr::recode(sales$condition,
                        "építés alatt" = NA_character_,
                        "beköltözheto" = NA_character_,
                        default=NULL,
                        missing=NULL)
summary(sales$condition)
```

Recode the categories of the variable "floor":
```{r}
typeof(sales$floor)
table(sales$floor)

sales$floor <- dplyr::recode(sales$floor,
                             "szuterén" = NA_character_,
                             "5" = "5+",
                             "6" = "5+",
                             "7" = "5+",
                             "8" = "5+",
                             "9" = "5+",
                             "10 felett" = "5+",
                             default=NULL,
                             missing=NULL)
table(sales$floor)
```

Recode the categories of the variable "heating":
```{r}
table(sales$heating)
sales$heating <- dplyr::recode(sales$heating,
                             "cserépkályha" = "Other",
                             "egyéb" = "Other",
                             "fan-coil" = "Other",
                             "gázkazán" = "Other",
                             "geotermikus" = "Other",
                             "távfutés" = "Other",
                             "távfutés egyedi méréssel" = "Other",
                             default=NULL,
                             missing=NULL)
table(sales$heating)
```

Recode the categories of the variable "orient":
```{r}
table(sales$orient)
sales$orient <- dplyr::recode(sales$orient,
                             "délkelet" = "dél",
                             "délnyugat" = "dél",
                             "északkelet" = "észak",
                             "északnyugat" = "észak",
                             default=NULL,
                             missing=NULL)
table(sales$orient)
```

Recode the categories of the variable "utility":
```{r}
table(sales$utility)
sales <- within(sales, {
  utility[utility == "félkomfortos"] <- NA
  utility[utility == "komfort nélküli"] <- NA
  })
```

No need to recode the variables:
  - aircon
  - xxx
  
Here's a summary of the cleaned data:
```{r}
sales <- droplevels(sales)
str(sales)
summary(sales)
```



## Explore the data
### Summary information
In this section, we create additional variables with mutate() and then use group_by() and summarise() from the dplyr package to take a first look at the data. In particular, the group_by() function is used to generate summary statistics from the data frame within strata defined by a variable.

Let's creating a new variables, the price per square meter:
```{r}
sales <- dplyr::mutate(sales, ppsm = price/area)
```

Let's look at the variations per location:
```{r}
# create a separate data frame that splits the original data frame by district/varos
locations <- dplyr::group_by(sales, district, varos)

dplyr::summarise(locations, 
                 total.count = n(),
                 avg.price = round(mean(price, na.rm=TRUE), 1),                 
                 median.price = round(median(price, na.rm=TRUE), 1),
                 avg.area = round(mean(area, na.rm=TRUE), 1),
                 median.area = round(median(area, na.rm=TRUE), 1),
                 avg.ppsm = mean(ppsm, na.rm=TRUE)*1000,
                 median.ppsm = median(ppsm, na.rm=TRUE)*1000)
```

Let's look at the variations with floor:
```{r}
floors <- dplyr::group_by(sales, floor, district=="5.ker")
dplyr::summarise(floors,
                 total.count = n(),
                 median.ppsm = round(median(ppsm, na.rm=TRUE)*1000, 1))
```

Let's look at the variations with heating system:
```{r}
heatings <- dplyr::group_by(sales, heating)
dplyr::summarise(heatings,
                 total.count = n(),
                 median.ppsm = round(median(ppsm, na.rm=TRUE)*1000, 1))
```
Looking at the heating systems is already interesting since I can spot potential confounders. For instance, the data here suggests that "házközponti" leads to the highest price per square meter. In reality, it is due to the fact that the building central heating is mainly present in the old buildings of the very centre.

Let's look at the variations with "view":
```{r}
views <- dplyr::group_by(sales, view)
dplyr::summarise(views,
                 total.count = n(),
                 median.ppsm = round(median(ppsm, na.rm=TRUE)*1000, 1))
```

### Identify confounders
I found a good summary of my thoughts on the topic at https://www.researchgate.net/post/How_do_I_find_confounding_variables:

"Whether you should check for confounding depends on the purpose of your model. Is it purely to predict the probability of an event? Or is it to test the hypothesis that a particular factor/variable causes outcome? So, if you are interested in testing causal relationships, then you must check for confounding. If your model is only for prediction, then checking is not important."

Let try techniques  on the continuous variables:
```{r}
sales.cont <- dplyr::select(sales, price:halfrooms, balcony:ppsm)

# covariances
#cov(sales.cont)

# correlation coefficients [see also "R in Action"]
#cor(sales.cont, y=NULL, use="pairwise.complete.obs", method=c("pearson","kendall","spearman"))

# testing correlations for significance
cor.test(sales.cont$price,sales.cont$balcony, alternative="two.side", method="pearson")

# visualize correlations with a correlogram
corrgram::corrgram(sales.cont,
                   order=FALSE,
                   lower.panel = panel.pie,
                   upper.panel = panel.pts,
                   text.panel = panel.txt,
                   main = "Correlogram of continuous variables")

# vizualise the relationships among numeric features using a scatterplot matrix
#psych::pairs.panels(sales.cont)
```

Let's now use mosaic plots to look at the categorical variables:
```{r}
str(sales)
sales.cat <- dplyr::select(sales, district:orient)
#sales.catt <- table(sales.cat)
#head(sales.catt)
#vcd::mosaic(sales.catt)
```

The dependent variable is "price". Although linear regression does not strictly require a normally distributed dependent variable, the model often fits better when this is true [see also Machine Learning with R, 2nd Edition]
```{r}
hist(sales$price[sales$price<100])
hist(sales$price, n=100)
hist(sales$ppsm, n=100)
```


## Make predictions

### Prepare the datasets
```{r}
# select the features of interest
sales.1 <- dplyr::select(sales, price, area, varos, floor, lift, heating)

# Randomly split the data into training and testing sets (based on the outcome)
set.seed(101)
inTrain <- caret::createDataPartition(sales.1$price, p=0.75,list = FALSE)
training.1 <- sales.1[inTrain,]
testing.1 <-  sales.1[-inTrain,]

# select the features of interest
sales.2 <- dplyr::select(sales, ppsm, area, varos, floor, lift, heating)

# Randomly split the data into training and testing sets (based on the outcome)
set.seed(1001)
inTrain <- caret::createDataPartition(sales.2$ppsm, p=0.75,list = FALSE)
training.2 <- sales.2[inTrain,]
testing.2 <-  sales.2[-inTrain,]
```
### Linear Regression (LM)
#### price ~ 5 independent variables (LM, no transformation)
```{r}
# Regression model on training set
price_mod_lm <- stats::lm(price ~ ., data=training.1)

# Summary statistics
summary(price_mod_lm)

# Plot residuals vs. observed values
kernlab::plot(na.exclude(training.1)$price, resid(price_mod_lm)/na.exclude(training.1)$price*100)

# Plot predicted values vs. observed values
kernlab::plot(na.exclude(training.1)$price,fitted(price_mod_lm))

# Predictions on testing set
testing.1 <- na.exclude(testing.1)
str(testing.1)

price_pred_lm <- predict(price_mod_lm, newdata=testing.1)

# Performance measure for regression
postResample(pred = price_pred_lm, obs = testing.1$price)
```

#### price ~ 5 independent variables (LM with caret, transform predictors)
```{r}
# Set the resampling method and options
ctrl <- caret::trainControl(## n-fold CV
                            method = "repeatedcv",
                            number = 10,
                            ## repeated k times
                            repeats = 3)

price_mod_lm.A <- caret::train(price ~ .,
                               data = na.exclude(training.1),
                               method = "lm",
                               tuneLength = 15,
                               trControl = ctrl,
                               preProc = c("center", "scale"))

# model summary                       
summary(price_mod_lm.A) 

# Plot residuals vs. observed values
kernlab::plot(na.exclude(training.1)$price, resid(price_mod_lm.A)/na.exclude(training.1)$price*100)

# Plot predicted values vs. observed values
kernlab::plot(na.exclude(training.1)$price,fitted(price_mod_lm.A))

# Predictions on testing set
testing.1 <- na.exclude(testing.1)
price_pred_lm.A <- predict(price_mod_lm.A, newdata=testing.1)

# Performance measure for regression
caret::postResample(pred = price_pred_lm.A, obs = testing.1$price)

# Calculate error on testing set
errTest = (price_pred_lm.A - testing.1$price)/testing.1$price * 100
summary(errTest)

mean(errTest, na.rm=TRUE)
sd(errTest, na.rm=TRUE) 
hist(errTest, breaks = pretty(-500:300, n=50))
```

Summary:
  - Centering and scaling don't change anything to the result of lm method
      Residual standard error = 24.8 and Adjusted R-squared = 0.70 
      RSME = 23.0 and Rsquared = 0.74 on testing set
  - "BoxCox" to resolve skewness results in much worse RMSE and Rsquared result
      Residual standard error = 29.8 and Adjusted R-squared = 0.57 
      RSME = 28.6 and Rsquared = 0.59 on testing set
  - CV and repeats don't have any impact on the calcualtion

#### price ~ 5 independent variables (LM with caret, transform outcome and predictors)
We first pre-process all the variables, i.e. the outcome and predictor(s):
```{r}
# skewness
e1071::skewness(sales.1$price, na.rm = T)
e1071::skewness(sales.1$area, na.rm = T)

# define the transformation to remove skewness, center and scale
trans <- caret::preProcess(sales.1,
                           method = c("BoxCox", "center", "scale"))

# apply the transformation
sales.1.trans <- predict(trans, sales.1)

# impute missing variables

# filter for near-zero variance predictors
caret::nearZeroVar(sales.1.trans)

# find correlations

# create dummy variables

# feature engineering

```

We now use CARET with lm method:
```{r}
# training and testing sets
training.1.trans <- sales.1.trans[inTrain,]
testing.1.trans <-  sales.1.trans[-inTrain,]

# Set the resampling method and options
ctrl <- caret::trainControl(## n-fold CV
                            method = "repeatedcv",
                            number = 10,
                            ## repeated k times
                            repeats = 3)

price_mod_lm.B <- caret::train(price ~ .,
                               data = na.exclude(training.1.trans),
                               method = "lm",
                               tuneLength = 15,
                               trControl = ctrl)

# model summary                       
summary(price_mod_lm.B) 

# Plot residuals vs. observed values
kernlab::plot(na.exclude(training.1.trans)$price,
              resid(price_mod_lm.B)/na.exclude(training.1.trans)$price*100)

# Plot predicted values vs. observed values
kernlab::plot(na.exclude(training.1.trans)$price,fitted(price_mod_lm.B))

# Predictions on testing set
testing.1.trans <- na.exclude(testing.1)
price_pred_lm.B <- predict(price_mod_lm.B, newdata=testing.1.trans)

# Performance measure for regression
caret::postResample(pred = price_pred_lm.B, obs = testing.1.trans$price)

# Calculate error on testing set
errTest = (price_pred_lm.B - testing.1.trans$price)/testing.1.trans$price * 100
summary(errTest)

mean(errTest, na.rm=TRUE)
sd(errTest, na.rm=TRUE) 
hist(errTest, breaks = pretty(-500:300, n=50))
```
Summary:
  - Centering and scaling of both outcome and predictor variables:
       - Residual standard error = 0.50 and Adjusted R-squared = 0.72 
       - RSME = 28.1 and Rsquared = 0.64 on testing set increase (worse)
       - err_mean = 34.9 and err_sd = 45.9
  - BoxCox transformation tend to improve the statistics:
       - Residual standard error = 0.36 and Adjusted R-squared = 0.86: model stats are better 
       - RSME = 27.6 and Rsquared = 0.64 on testing set are slightly better
       - err_mean = 11.4 and err_sd = 35.8
       






#### ppsm ~ 5 independent variables (LM with caret, transform predictors)
The lessons learnt from the previous analyses:
  - Use CARET package
  - Center and scale the data (did not change anything, but seems like good practice)
  - Do not resolve skewness with BoxCox transformation
  - Transform only the predictor variable(s)
  
```{r}
# Set the resampling method and options
ctrl <- caret::trainControl(## n-fold CV
                            method = "repeatedcv",
                            number = 10,
                            ## repeated k times
                            repeats = 3)

ppsm_mod_lm.A <- caret::train(ppsm ~ .,
                               data = na.exclude(training.2),
                               method = "lm",
                               tuneLength = 15,
                               trControl = ctrl,
                               preProc = c("center", "scale"))

# model summary                       
summary(ppsm_mod_lm.A) 

# Plot residuals vs. observed values
kernlab::plot(na.exclude(training.2)$ppsm, resid(ppsm_mod_lm.A)/na.exclude(training.2)$ppsm*100)

# Plot predicted values vs. observed values
kernlab::plot(na.exclude(training.2)$ppsm,fitted(ppsm_mod_lm.A))

# Predictions on testing set
testing.2 <- na.exclude(testing.2)
ppsm_pred_lm.A <- predict(ppsm_mod_lm.A, newdata=testing.2)

# Performance measure for regression
caret::postResample(pred = ppsm_pred_lm.A, obs = testing.2$ppsm)

# Calculate error on testing set
errTest = (ppsm_pred_lm.A - testing.2$ppsm)/testing.2$ppsm * 100
summary(errTest)

mean(errTest, na.rm=TRUE)
sd(errTest, na.rm=TRUE) 
hist(errTest, breaks = pretty(-500:300, n=50))
```
Summary:
  - Residual standard error = 0.21 and Adjusted R-squared = 0.39 
  - RSME = 0.18 and Rsquared = 0.39 on testing set

The standard deviation of the error is "only" 25%, but the mean(errTest) is huge with 5.8. Using ppsm instead of price degrades the prediciton

### Regression tree (CART with rpart)
The analysis below is with parameter optimisation using caret
```{r}
# Set the resampling method and cross-validation options
ctrl <- caret::trainControl(## n-fold CV
                            method = "cv",
                            number = 10,
                            ## repeated k times
                            repeats = 0)

cpGrid = expand.grid( .cp = seq(1e-7,1e-6,1e-7)) 

# Perform the cross validation
price_cv_rpart <- caret::train(price ~ .,
                               data = training.1,
                               na.action = na.omit,
                               method = "rpart",
                               trControl = ctrl,
                               tuneGrid = cpGrid,
                               preProc = c("center", "scale"))

# Cross-validation results
print(price_cv_rpart)
plot(price_cv_rpart)

# Create a CART model
price_mod_rpart <- rpart::rpart(price ~ ., data = training.1, cp = 9e-07)

# Make predictions
price_pred_rpart = predict(price_mod_rpart, newdata = testing.1)

# model summary                       

# Plot residuals vs. observed values
obs <- training.1$price
fit <- predict(price_mod_rpart)
kernlab::plot(obs, (fit-obs)/obs *100)

# Plot predicted values vs. observed values
kernlab::plot(obs,fit)

# Predictions on testing set
price_pred_rpart <- predict(price_mod_rpart, newdata=testing.1)

# Performance measure for regression
caret::postResample(pred = price_pred_rpart, obs = testing.1$price)

# Calculate error on testing set
errTest = (price_pred_rpart - testing.1$price)/testing.1$price * 100
summary(errTest)

mean(errTest, na.rm=TRUE)
sd(errTest, na.rm=TRUE) 
hist(errTest, breaks = pretty(-160:160, n=50))
```

### Random forest
The analysis below is with parameter optimisation using caret. The parameters to optimize with resampling are "mtry" and "ntree".

```{r}
# Set the resampling method and cross-validation options
ctrl <- caret::trainControl(## n-fold CV
                            method = "cv",
                            number = 10,
                            ## repeated k times
                            repeats = 3)

# Set constant model parameter
ntree <- 1000

# Perform the cross validation
set.seed(7)
mtryGrid <- expand.grid(.mtry=c(1:5))
price_cv_rf <- train(price ~ ., 
                      data=training.1, 
                      na.action = na.omit,
                      method="rf", 
                      metric="RMSE", 
                      tuneGrid=mtryGrid, 
                      trControl=ctrl)
print(price_train_rf)
plot(price_train_rf)

# Create a random forest model
price_mod_rf <- randomForest::randomForest(price ~ ., 
                                              data = training.1,
                                              na.action = na.omit,
                                              importance = TRUE,
                                              ntree = 1000,
                                              mtry = 5)

# Variables of importance
varImpPlot(price_mod_rf)

# Plot residuals vs. observed values
obs <- na.exclude(training.1)$price
fit <- predict(price_mod_rf)
kernlab::plot(obs, (fit-obs)/obs *100)

# Plot predicted values vs. observed values
kernlab::plot(obs,fit)

# Make predictions on testing set
price_pred_rf = predict(price_mod_rf, newdata = testing.1)

# Performance measure for regression
caret::postResample(pred = price_pred_rf, obs = testing.1$price)

# Calculate error on testing set
errTest = (price_pred_rf - testing.1$price)/testing.1$price * 100
summary(errTest)

mean(errTest, na.rm=TRUE)
sd(errTest, na.rm=TRUE) 
hist(errTest, breaks = pretty(-160:160, n=50))
```














## Answer some modelling questions

### Randomly split the data into training and testing sets (based on the predictors)

### Filter with dplyr
testingSet <- dplyr::filter(testingSet, area >=30 & area <= 100)


Is my model performing better for a subset of the data, e.g. in a given district?
Do I need to scale all my variables before the analysis?

When I look at the GML model summary:
  - Deviance residual: ??
  - Coefficients (Estimate): gives the sign and level of correlation. Factors are all compared to a baseline factor! Can I say that a Lift is increases the price by 54'000 HUF/m2 based on the coefficient? Yes, assuming I don't have confounders... This is the debate between predictive models and finding causal relationships.
  - Null deviance: ??
  - Residual deviance: ??
  - AIC = Akaike Information Criterion: ??

Tip to name my models: y.training_data.model, e.g. "price.sales1.glm"
>> .algorithm.


Does it improve the prediction if I train on the complete dataset, but thenpredict on a narrower range of area? With CART, it's not obvious at all.

## Answer real-world questions


Some examples of real-world questions: 
1) Looking at the histogram of errors, whioch properties seem undervalued? 
2) What features are driving property prices?
3) What is the premium if there is an elevator? Talk in "ppsm" or "price"?
```{r}
boxplot(ppsm~lift, data=sales, outline=F) #outline=F removes the outliers
median(sales.2$ppsm[sales.2$lift=="van"],na.rm=T)
median(sales.2$ppsm[sales.2$lift=="nincs"],na.rm=T)

```

